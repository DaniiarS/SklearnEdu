{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a0f59ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99984dbc",
   "metadata": {},
   "source": [
    "## Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f2e63fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__( self, text, score ):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    \n",
    "    # Categorizes a score into sentiment\n",
    "    def get_sentiment( self ):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: \n",
    "            return Sentiment.POSITIVE\n",
    "\n",
    "class ReviewContainer:\n",
    "    \n",
    "    def __init__( self, reviews ):\n",
    "        self.reviews = reviews\n",
    "    \n",
    "    def get_text( self ):\n",
    "        return [ review.text for review in self.reviews ]\n",
    "    \n",
    "    def get_sentiment( self ):\n",
    "        return [ review.sentiment for review in self.reviews ]\n",
    "    \n",
    "    def evenly_distribute( self ):\n",
    "        negative = list( filter( lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews ) )\n",
    "        positive = list( filter( lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews ) )\n",
    "        \n",
    "        negative_size = len( negative )\n",
    "        positive_shrunk = positive[0: negative_size ]\n",
    "        \n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle( self.reviews )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f26a88",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "023ac6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/books_small_10000.txt'\n",
    "reviews = []\n",
    "\n",
    "with open( file_name, 'r' ) as f:\n",
    "    for line in f:\n",
    "        review = json.loads( line )\n",
    "        reviews.append( Review( review['reviewText'], review['overall'] ) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "817aa9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[7].sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e8b02",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1c3d304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split( reviews, test_size = 0.33, random_state = 42 )\n",
    "\n",
    "training_container = ReviewContainer(training)\n",
    "test_container = ReviewContainer(test)\n",
    "\n",
    "training_container.evenly_distribute()\n",
    "test_container.evenly_distribute()\n",
    "len( training_container.reviews )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3af8ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6700\n",
      "3300\n"
     ]
    }
   ],
   "source": [
    "print( len(training) )\n",
    "print( len(test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fa333c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = training_container.get_text()\n",
    "train_y = training_container.get_sentiment()\n",
    "\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54424516",
   "metadata": {},
   "source": [
    "### Bags of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4e64ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the number of appearance of each word in the sentence an repressents it in a vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "# print( train_x[0] )\n",
    "# print( train_x_vectors[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f248d1",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082330c",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ed23f576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Double is definitely not one of Pelecanos's best efforts.  The story is threadbare and makes little sense as it goes from minor burglary to intense shoot outs and killings for no real reason.  The sub plots are meaningless and the dialogue is mostly laughable.  Pelecanos really struggles with writing in the present day.. he is much better with the 70's and 80's where he can show his knowledge of music and cars from those eras.  As a DC native I do enjoy the DC setting, but even that gets old and seems mostly to be filler in this book.  Look for very early Pelecanos books to read something really exciting.\n",
      "['POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel ='rbf')\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "print( test_x[0] )\n",
    "print( clf_svm.predict(test_x_vectors[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd78ee2",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d1cab225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Again a masterful telling of a story.  My only regret is that I have to wait until Oct. 28th to find out the ending.  Well done!\n",
      "['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_tree.fit( train_x_vectors, train_y )\n",
    "\n",
    "print( test_x[100] )\n",
    "print( clf_tree.predict( test_x_vectors[100] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9e954",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3e54afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't like this book, the story is not believable. The characters weren't develop, there was no chemistry between the hero and heroine.\n",
      "['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit( train_x_vectors.toarray(), train_y )\n",
    "\n",
    "print( test_x[250] )\n",
    "print( clf_gnb.predict(test_x_vectors[250].toarray()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8fa79d",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5dcacb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I haven't read a urban novel in years. This has a good storyline, can't wait to read the sequel! I like the way how the author went into detail, about what the main characters were thinking. I have a feeling Khalil is going to go bonkers on Donte and a few other people.\n",
      "['POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit( train_x_vectors, train_y )\n",
    "\n",
    "print( test_x[45] )\n",
    "print( clf_log.predict( test_x_vectors[45] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab169399",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b435d917",
   "metadata": {},
   "source": [
    "#### Mean Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "170eb775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8100961538461539\n",
      "0.6322115384615384\n",
      "0.6610576923076923\n",
      "0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "print( clf_svm.score( test_x_vectors, test_y ) )\n",
    "print( clf_tree.score( test_x_vectors, test_y ) )\n",
    "print( clf_gnb.score( test_x_vectors.toarray(), test_y ) )\n",
    "print( clf_log.score( test_x_vectors, test_y ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c5d11f",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1d930c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80871671 0.81145585]\n",
      "[0.62222222 0.64168618]\n",
      "[0.65693431 0.66508314]\n",
      "[0.80291971 0.80760095]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print( f1_score( test_y, clf_svm.predict( test_x_vectors ), average = None, labels = [ Sentiment.POSITIVE, Sentiment.NEGATIVE ] ) )\n",
    "print( f1_score( test_y, clf_tree.predict( test_x_vectors ), average = None, labels = [ Sentiment.POSITIVE, Sentiment.NEGATIVE ] ) )\n",
    "print( f1_score( test_y, clf_gnb.predict( test_x_vectors.toarray() ), average = None, labels = [ Sentiment.POSITIVE, Sentiment.NEGATIVE ] ) )\n",
    "print( f1_score( test_y, clf_log.predict( test_x_vectors ), average = None, labels = [ Sentiment.POSITIVE, Sentiment.NEGATIVE ] ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f2ba27",
   "metadata": {},
   "source": [
    "#### Testing on Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "611044c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872 436 436\n",
      "208 208\n"
     ]
    }
   ],
   "source": [
    "# train_y.count( Sentiment.POSITIVE )\n",
    "# print( len(train_y), train_y.count( Sentiment.POSITIVE ), train_y.count( Sentiment.NEGATIVE ) )\n",
    "# print( test_y.count( Sentiment.POSITIVE ), test_y.count( Sentiment.NEGATIVE ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ef121017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE', 'NEGATIVE', 'POSITIVE', 'POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = [ \"Bad book\", \"I think this book is not good\", \"I liked reading this book\", \"I recommend this book, nice experience!\" ]\n",
    "\n",
    "test_set_vectors = vectorizer.transform( test_set )\n",
    "clf_log.predict( test_set_vectors )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9622c9",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a7cc88",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "706b3bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open( './models/sentiment/log_classifier.pkl', 'wb' ) as f:\n",
    "    pickle.dump( clf_log, f )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f79df1a",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8465d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( './models/sentiment/log_classifier.pkl', 'rb' ) as f:\n",
    "    new_clf = pickle.load( f )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
